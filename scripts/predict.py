# scripts/predict.py

import pandas as pd
import numpy as np
import torch
import joblib
import os
import matplotlib.pyplot as plt
from tqdm import tqdm
from transformers import PatchTSTForPrediction

# --- –ò–º–ø–æ—Ä—Ç—ã ---
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from src.config import *
# --- –ö–æ–Ω–µ—Ü –±–ª–æ–∫–∞ ---

def run_prediction():
    print("üöÄ –ó–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π...")
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"--- –ò—Å–ø–æ–ª—å–∑—É–µ–º–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device.upper()} ---")

    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
    print("1/5: –ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π, –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–≤ –∏ —Å–∫–µ–π–ª–µ—Ä–æ–≤...")
    try:
        model_reg = PatchTSTForPrediction.from_pretrained(REG_MODEL_PATH).to(device)
        model_prob = PatchTSTForPrediction.from_pretrained(PROB_MODEL_PATH).to(device)
        preprocessor_reg = joblib.load(REG_PREPROCESSOR_PATH)
        preprocessor_prob = joblib.load(PROB_PREPROCESSOR_PATH)
        # –ó–ê–ì–†–£–ñ–ê–ï–ú –°–ö–ï–ô–õ–ï–†–´
        scalers_reg = joblib.load(REG_PREPROCESSOR_PATH.replace('.pkl', '_scalers.pkl'))
        scalers_prob = joblib.load(PROB_PREPROCESSOR_PATH.replace('.pkl', '_scalers.pkl'))
    except Exception as e:
        print(f"–û–®–ò–ë–ö–ê: –ó–∞–≥—Ä—É–∑–∫–∞ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –Ω–µ —É–¥–∞–ª–∞—Å—å. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ train.py –æ—Ç—Ä–∞–±–æ—Ç–∞–ª. {e}")
        return
    model_reg.eval(); model_prob.eval()

    # 2. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    print("2/5: –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è...")
    train_df = pd.read_csv(RAW_TRAIN_CANDLES_PATH, parse_dates=['begin'])
    test_df = pd.concat([
        pd.read_csv(RAW_PUBLIC_TEST_CANDLES_PATH, parse_dates=['begin']),
        pd.read_csv(RAW_PRIVATE_TEST_CANDLES_PATH, parse_dates=['begin'])
    ], ignore_index=True)
    
    full_candles_df = pd.concat([train_df, test_df], ignore_index=True).sort_values(by=['ticker', 'begin'])
    features_df = pd.read_parquet(PROCESSED_TS_FEATURES_PATH).set_index(['ticker', 'begin'])
    
    data_to_predict = pd.merge(
        features_df,
        full_candles_df[['ticker', 'begin', 'close']].rename(columns={'close': 'original_close'}), # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º, —á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–∞
        on=['ticker', 'begin'],
        how='left' # left join, —á—Ç–æ–±—ã —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ –∏–∑ features_df
    )
    data_to_predict = data_to_predict.sort_values(by=['ticker', 'begin']).reset_index(drop=True)

    # 3. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
    print("3/5: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –¥–ª—è –∫–∞–∂–¥–æ–π —Ç–µ—Å—Ç–æ–≤–æ–π –¥–∞—Ç—ã...")
    all_predictions = []
    
    num_context_features_reg = len(preprocessor_reg.control_columns)
    num_context_features_prob = len(preprocessor_prob.control_columns)

    for ticker in tqdm(test_df['ticker'].unique(), desc="–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ø–æ —Ç–∏–∫–µ—Ä–∞–º"):
        # –ü–æ–ª—É—á–∞–µ–º —Å–∫–µ–π–ª–µ—Ä—ã –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —Ç–∏–∫–µ—Ä–∞
        scaler_key = (ticker,)
        scaler_reg = scalers_reg.get(scaler_key)
        scaler_prob = scalers_prob.get(scaler_key)
        if not scaler_reg or not scaler_prob:
            print(f"  ! –í–Ω–∏–º–∞–Ω–∏–µ: –°–∫–µ–π–ª–µ—Ä—ã –¥–ª—è —Ç–∏–∫–µ—Ä–∞ {ticker} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ü—Ä–æ–ø—É—Å–∫.")
            continue

        for date in test_df[test_df['ticker'] == ticker]['begin']:
            history = data_to_predict[(data_to_predict['ticker'] == ticker) & (data_to_predict['begin'] < date)].copy()
            if len(history) < CONTEXT_LENGTH: continue

            for i in range(1, PREDICTION_LENGTH + 1):
                history[f'target_return_{i}d'], history[f'target_grew_{i}d'] = 0.0, 0.0

            proc_reg = preprocessor_reg.preprocess(history)
            proc_prob = preprocessor_prob.preprocess(history)
            
            ctx_reg_vals = proc_reg.drop(columns=['ticker', 'begin']).iloc[-CONTEXT_LENGTH:, :num_context_features_reg].values
            ctx_prob_vals = proc_prob.drop(columns=['ticker', 'begin']).iloc[-CONTEXT_LENGTH:, :num_context_features_prob].values
            
            ctx_reg = torch.tensor(ctx_reg_vals, dtype=torch.float32).unsqueeze(0).to(device)
            ctx_prob = torch.tensor(ctx_prob_vals, dtype=torch.float32).unsqueeze(0).to(device)
            
            with torch.no_grad():
                preds_reg_scaled = model_reg(past_values=ctx_reg).prediction_outputs
                preds_prob_scaled = model_prob(past_values=ctx_prob).prediction_outputs

            # --- –§–ò–ù–ê–õ–¨–ù–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï ---
            # –í—ã—Ö–æ–¥ –º–æ–¥–µ–ª–∏ –∏–º–µ–µ—Ç —Ñ–æ—Ä–º—É (batch_size, prediction_length, num_targets)
            # –í –Ω–∞—à–µ–º —Å–ª—É—á–∞–µ —ç—Ç–æ (1, 20, 20). –ù–∞–º –Ω—É–∂–Ω–∞ –¥–∏–∞–≥–æ–Ω–∞–ª—å.
            # –ù–æ —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ, num_targets=1, –∏ —Ñ–æ—Ä–º–∞ (1, 20, 1). –£–±–∏—Ä–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å.
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ numpy
            preds_reg_np = preds_reg_scaled.cpu().numpy()
            preds_prob_np = preds_prob_scaled.cpu().numpy()

            # –£–±–∏—Ä–∞–µ–º batch-—Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å (–ø–µ—Ä–≤—É—é)
            preds_reg_np = preds_reg_np.squeeze(0)
            preds_prob_np = preds_prob_np.squeeze(0)
            
            # –ï—Å–ª–∏ –ø–æ—Å–ª–µ–¥–Ω—è—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å = 1, —É–±–∏—Ä–∞–µ–º –∏ –µ–µ. –§–æ—Ä–º–∞ —Å—Ç–∞–Ω–µ—Ç (20,)
            if preds_reg_np.shape[-1] == 1:
                preds_reg_np = preds_reg_np.squeeze(-1)
            
            if preds_prob_np.shape[-1] == 1:
                preds_prob_np = preds_prob_np.squeeze(-1)

            # –¢–µ–ø–µ—Ä—å —Ñ–æ—Ä–º–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å (20,) –∏–ª–∏ (20, 20). –°–∫–µ–π–ª–µ—Ä –æ–∂–∏–¥–∞–µ—Ç (n_samples, n_features)
            # –í –Ω–∞—à–µ–º —Å–ª—É—á–∞–µ —ç—Ç–æ (1, 20) –¥–ª—è –æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è.
            if preds_reg_np.ndim == 1:
                preds_reg_np = preds_reg_np.reshape(1, -1) # (20,) -> (1, 20)
            if preds_prob_np.ndim == 1:
                preds_prob_np = preds_prob_np.reshape(1, -1) # (20,) -> (1, 20)
            
            preds_reg_unscaled = scaler_reg.inverse_transform(preds_reg_np)
            preds_prob_unscaled = scaler_prob.inverse_transform(preds_prob_np)
            
            record = {'ticker': ticker, 'begin': date}
            record['pred_return_1d'] = preds_reg_unscaled[0, 0]
            record['pred_return_20d'] = np.sum(preds_reg_unscaled[0, :])
            record['pred_prob_up_1d'] = np.clip(preds_prob_unscaled[0, 0], 0, 1)
            record['pred_prob_up_20d'] = np.clip(preds_prob_unscaled[0, 19], 0, 1)
            all_predictions.append(record)

    submission_df = pd.DataFrame(all_predictions)
    
    # 4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    print("4/5: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ submission.csv...")
    final_cols = ['ticker', 'begin', 'pred_return_1d', 'pred_return_20d', 'pred_prob_up_1d', 'pred_prob_up_20d']
    submission_df.reindex(columns=final_cols).fillna(0.5).to_csv("submission.csv", index=False)
    print("  ‚úì Submission —Å–æ—Ö—Ä–∞–Ω–µ–Ω.")
    if not submission_df.empty: print(submission_df.head().to_string())

    # 5. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    print("5/5: –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π...")
    if not submission_df.empty:
        plot_predictions(submission_df, train_df, test_df, submission_df['ticker'].iloc[0])

def plot_predictions(submission_df, train_df, test_df, ticker):
    ticker_preds = submission_df[submission_df['ticker'] == ticker].sort_values(by='begin')
    ticker_train = train_df[train_df['ticker'] == ticker]
    ticker_test = test_df[test_df['ticker'] == ticker]
    if ticker_preds.empty or ticker_train.empty or ticker_test.empty: return
    full_history = pd.concat([ticker_train, ticker_test]).sort_values(by='begin')
    full_history['close_prev'] = full_history['close'].shift(1)
    plot_df = pd.merge(ticker_preds, full_history[['begin', 'close_prev']], on='begin', how='left').ffill()
    plot_df['pred_price'] = plot_df['close_prev'] * (1 + plot_df['pred_return_1d'])
    plt.figure(figsize=(15, 7))
    history_plot = ticker_train.tail(90)
    plt.plot(history_plot['begin'], history_plot['close'], label=f'–ò—Å—Ç–æ—Ä–∏—è —Ü–µ–Ω—ã {ticker}')
    plt.plot(ticker_test['begin'], ticker_test['close'], label=f'–†–µ–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞ (—Ç–µ—Å—Ç)', color='gray', linestyle='--')
    plt.plot(plot_df['begin'], plot_df['pred_price'], label='–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è —Ü–µ–Ω–∞', linestyle='-', marker='o', color='red', markersize=4)
    plt.title(f'–ü—Ä–æ–≥–Ω–æ–∑ –¥–≤–∏–∂–µ–Ω–∏—è —Ü–µ–Ω—ã –¥–ª—è {ticker}'); plt.xlabel('–î–∞—Ç–∞'); plt.ylabel('–¶–µ–Ω–∞')
    plt.legend(); plt.grid(True); plt.savefig(f'forecast_price_{ticker}.png'); plt.close()

if __name__ == '__main__':
    run_prediction()