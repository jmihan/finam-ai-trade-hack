import pandas as pd
import pandas_ta as ta
import numpy as np
from tqdm import tqdm

# --- –ë–ª–æ–∫ –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∏–º–ø–æ—Ä—Ç–∞ –ø—Ä–∏ –ª–æ–∫–∞–ª—å–Ω–æ–º –∑–∞–ø—É—Å–∫–µ ---
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
# --- –ö–æ–Ω–µ—Ü –±–ª–æ–∫–∞ ---

# –û–±–Ω–æ–≤–ª—è–µ–º –ø—É—Ç–∏ –≤ config.py, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
from src.config import * 

def generate_features():
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç train, public_test, private_test —Å–≤–µ—á–∏, –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –∏—Ö,
    –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–∫–µ—Ä–∞
    –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ parquet-—Ñ–∞–π–ª.
    """
    print("üöÄ –ó–∞–ø—É—Å–∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤...")

    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –í–°–ï–• –¥–∞–Ω–Ω—ã—Ö –æ —Å–≤–µ—á–∞—Ö
    print("1/5: –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö —Å–≤–µ—á–µ–π (train, public, private)...")
    
    # –û–ø—Ä–µ–¥–µ–ª–∏–º –ø—É—Ç–∏. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –æ–Ω–∏ –≤–µ—Ä–Ω—ã –∏–ª–∏ –¥–æ–±–∞–≤—å—Ç–µ –∏—Ö –≤ config.py
    # –ü—Ä–∏–º–µ—Ä –ø—É—Ç–µ–π, –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –ª–µ–∂–∞—Ç –≤ data/raw/
    base_path = '../data/raw/' if os.path.exists('../data/raw/') else 'data/raw/'
    train_candles_path = os.path.join(base_path, 'train_candles.csv')
    public_test_candles_path = os.path.join(base_path, 'public_test_candles.csv')
    private_test_candles_path = os.path.join(base_path, 'private_test_candles.csv')

    try:
        train_df = pd.read_csv(train_candles_path, parse_dates=['begin'])
        public_df = pd.read_csv(public_test_candles_path, parse_dates=['begin'])
        private_df = pd.read_csv(private_test_candles_path, parse_dates=['begin'])
    except FileNotFoundError as e:
        print(f"–û–®–ò–ë–ö–ê: –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª –¥–∞–Ω–Ω—ã—Ö: {e}. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç–∏.")
        return

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–∫–≤–æ–∑–Ω–æ–≥–æ —Ä–∞—Å—á–µ—Ç–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    df = pd.concat([train_df, public_df, private_df], ignore_index=True)
    
    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–∞ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ —Ä–∞—Å—á–µ—Ç–∞ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
    df = df.sort_values(by=['ticker', 'begin']).reset_index(drop=True)
    print(f"  ‚úì –í—Å–µ –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω—ã. –§–∏–Ω–∞–ª—å–Ω–∞—è —Ñ–æ—Ä–º–∞: {df.shape}")

    # 2. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    print("2/5: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    df['day_of_week'] = df['begin'].dt.dayofweek
    df['week_of_year'] = df['begin'].dt.isocalendar().week.astype(int)
    df['month'] = df['begin'].dt.month
    print("  ‚úì –ö–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å–æ–∑–¥–∞–Ω—ã.")

    # 3. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–∞—Å—Ç–æ–º–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ OHLCV
    print("3/5: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–∞—Å—Ç–æ–º–Ω—ã—Ö OHLCV –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    df['day_range_norm'] = (df['high'] - df['low']) / df['close']
    df['body_size_norm'] = (df['close'] - df['open']) / df['open']
    print("  ‚úì –ö–∞—Å—Ç–æ–º–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å–æ–∑–¥–∞–Ω—ã.")

    # 4. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¢–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –ê–Ω–∞–ª–∏–∑–∞ (TA)
    print("4/5: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è TA –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (RSI, MACD, BBands, Stochastic)...")
        
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–Ω–∞—á–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏, —á—Ç–æ–±—ã –ø–æ—Ç–æ–º –Ω–∞–π—Ç–∏ –Ω–æ–≤—ã–µ
    initial_columns = set(df.columns)

    # –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –¥–ª—è —Å–±–æ—Ä–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –≥—Ä—É–ø–ø
    processed_groups = []
        
    # tqdm –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –ø–æ —Ç–∏–∫–µ—Ä–∞–º
    for ticker, group in tqdm(df.groupby('ticker'), desc="–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–∏–∫–µ—Ä–æ–≤"):
        # –ö–æ–ø–∏—Ä—É–µ–º, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å SettingWithCopyWarning
        ticker_df = group.copy()
            
        # –†–∞—Å—á–µ—Ç –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —Ç–∏–∫–µ—Ä–∞
        # `append=True` –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç ticker_df –Ω–∞ –º–µ—Å—Ç–µ
        ticker_df.ta.rsi(length=14, append=True)
        ticker_df.ta.macd(append=True)
        ticker_df.ta.bbands(length=20, append=True)
        ticker_df.ta.stoch(append=True)
            
        processed_groups.append(ticker_df)

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—Å–µ—Ö —Ç–∏–∫–µ—Ä–æ–≤ –æ–±—Ä–∞—Ç–Ω–æ –≤ –æ–¥–∏–Ω DataFrame
    df = pd.concat(processed_groups)

    # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –Ω–∞—Ö–æ–¥–∏–º –≤—Å–µ –Ω–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –±—ã–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã pandas_ta
    final_columns = set(df.columns)
    ta_cols = list(final_columns - initial_columns)

    print(f"  ‚úì TA –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å–æ–∑–¥–∞–Ω—ã. –ù–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {ta_cols}")
        
    # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ MACD, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É
    cols_to_drop = [col for col in ta_cols if col.startswith('MACD_') or col.startswith('MACDs_')]
    df = df.drop(columns=cols_to_drop, errors='ignore')
    # –û–±–Ω–æ–≤–ª—è–µ–º —Å–ø–∏—Å–æ–∫ ta_cols –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è
    ta_cols = [col for col in ta_cols if col not in cols_to_drop]

    # –ü—Ä–∏–º–µ–Ω—è–µ–º forward fill –∏ backward fill –í–ù–£–¢–†–ò –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø—ã —Ç–∏–∫–µ—Ä–æ–≤
    print("  > –û–±—Ä–∞–±–æ—Ç–∫–∞ NaN –∑–Ω–∞—á–µ–Ω–∏–π –≤ TA –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö...")
    df[ta_cols] = df.groupby('ticker')[ta_cols].transform(lambda x: x.ffill().bfill())

    print("  ‚úì TA –ø—Ä–∏–∑–Ω–∞–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã.")

    # 5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    print("5/5: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    
    # –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –∫–ª—é—á–µ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –∏ –Ω–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    feature_columns = [
        'ticker', 'begin',
        'open', 'close', 'high', 'low', 'volume', # –û—Å—Ç–∞–≤–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ OHLCV
        'day_of_week', 'week_of_year', 'month',
        'day_range_norm', 'body_size_norm'
    ] + [col for col in ta_cols if col in df.columns]

    final_df = df[feature_columns].copy()
    
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é, –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    os.makedirs(os.path.dirname(PROCESSED_TS_FEATURES_PATH), exist_ok=True)

    final_df.to_parquet(PROCESSED_TS_FEATURES_PATH, index=False)
    
    print(f"\n‚úÖ –ì–æ—Ç–æ–≤–æ! –ü—Ä–∏–∑–Ω–∞–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {PROCESSED_TS_FEATURES_PATH}")
    print(f"   –§–∏–Ω–∞–ª—å–Ω–∞—è —Ñ–æ—Ä–º–∞ –¥–∞–Ω–Ω—ã—Ö —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏: {final_df.shape}")
    print("\n   –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
    print(final_df.isnull().sum())
    print("\n   –ü—Ä–∏–º–µ—Ä —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
    print(final_df.tail().to_string())


if __name__ == '__main__':
    generate_features()